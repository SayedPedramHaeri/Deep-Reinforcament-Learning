{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdc63d1d",
   "metadata": {},
   "source": [
    "# Project: Deep Reinforcement Learning - CartPole Environment\n",
    "**Author:** Sayed Pedram Haeri Boroujeni  \n",
    "**Position:** PhD Student, Clemson University  \n",
    "**Affiliation:** Department of Computer Science  \n",
    "**Email:** shaerib@g.clemson.edu  \n",
    "**Date Created:** June 10, 2025  \n",
    "**Last Updated:** June 15, 2025 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a5a0ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d3332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbab38d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Space: Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
      "Action Space: Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "print(\"State Space:\", env.observation_space)\n",
    "print(\"Action Space:\", env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5fc85cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.00517726,  0.18968324,  0.03895573, -0.24300396], dtype=float32), 1.0, False, False, {})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 00:27:52.478 python[3861:156041] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-06-11 00:27:52.478 python[3861:156041] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "env.render()\n",
    "print(env.step(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56b98cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → state=[ 0.00897092  0.38422772  0.03409565 -0.5231492 ], reward=1.0, terminated=False, truncated=False\n"
     ]
    }
   ],
   "source": [
    "random_action = env.action_space.sample()\n",
    "next_state, reward, terminated, truncated, info = env.step(random_action)\n",
    "print(f\"  → state={next_state}, reward={reward}, terminated={terminated}, truncated={truncated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1586ee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5764c37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..... Episode 1 is started ........\n",
      "  → state=[-0.00962474  0.02195498  0.00201946  0.01992132]\n",
      "  → action=1, state=[-0.00918564  0.21704791  0.00241788 -0.27212375], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[-0.00484468  0.41213527 -0.00302459 -0.5640431 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.00339803  0.21705589 -0.01430545 -0.2723146 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.00773914  0.02214096 -0.01975175  0.01582223], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.00818196  0.21754052 -0.0194353  -0.28302658], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.01253277  0.4129342  -0.02509583 -0.58177537], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.02079146  0.21817271 -0.03673134 -0.2971025 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.02515491  0.02359311 -0.04267339 -0.01622657], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.02562677 -0.1708917  -0.04299792  0.2626929 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.02220894 -0.36537436 -0.03774406  0.54150975], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.01490145 -0.1697428  -0.02691387  0.23717728], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.0115066   0.02575312 -0.02217033 -0.06387211], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.01202166  0.2211858  -0.02344777 -0.36346665], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.01644538  0.02640482 -0.0307171  -0.07826848], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.01697347 -0.16826363 -0.03228247  0.20456703], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.0136082  -0.3629094  -0.02819113  0.48689416], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.00635001 -0.16740125 -0.01845325  0.18546137], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.00300199  0.0279798  -0.01474402 -0.11298525], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.00356158  0.22330987 -0.01700372 -0.41028312], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.00802778  0.41866872 -0.02520939 -0.7082779 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.01640115  0.6141306  -0.03937494 -1.0087883 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.02868377  0.80975544 -0.05955071 -1.3135713 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.04487887  0.61543566 -0.08582214 -1.0401059 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.05718759  0.8115865  -0.10662425 -1.35845   ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.07341932  1.0078717  -0.13379325 -1.682494  ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.09357675  1.2042656  -0.16744314 -2.01367   ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.11766206  1.0112333  -0.20771654 -1.7771698 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.13788673  1.2080016  -0.24325994 -2.1266081 ], reward=1.0, terminated=True, truncated=False\n",
      "..... Episode 2 is started ........\n",
      "  → state=[0.02515008 0.02533702 0.03073025 0.03696854]\n",
      "  → action=1, state=[ 0.02565682  0.22000512  0.03146962 -0.24586248], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[0.03005692 0.02444817 0.02655237 0.05657825], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.03054588  0.21917954  0.02768393 -0.22761036], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[0.03492947 0.02367313 0.02313172 0.07367492], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.03540293 -0.17177267  0.02460522  0.37356532], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.03196748 -0.36723536  0.03207653  0.67390376], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.02462278 -0.56278807  0.0455546   0.9765109 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.01336701 -0.36830568  0.06508482  0.69847834], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.0060009  -0.17414366  0.07905439  0.42697337], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.00251803 -0.37029108  0.08759385  0.74349344], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[-0.0048878  -0.5665058   0.10246372  1.0624068 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[-0.01621791 -0.37287867  0.12371186  0.803561  ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[-0.02367548 -0.17965041  0.13978308  0.55221236], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[-0.02726849  0.01326029  0.15082733  0.30663124], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[-0.02700329 -0.18365301  0.15695995  0.64282316], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[-0.03067635 -0.3805741   0.16981642  0.9805307 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[-0.03828783 -0.5775148   0.18942703  1.321379  ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[-0.04983813 -0.7744572   0.21585461  1.6668674 ], reward=1.0, terminated=True, truncated=False\n",
      "..... Episode 3 is started ........\n",
      "  → state=[-0.00174568 -0.02170564  0.01031587  0.00846399]\n",
      "  → action=1, state=[-0.00217979  0.17326686  0.01048515 -0.2809464 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.00128554  0.36823767  0.00486622 -0.570304  ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.0086503   0.5632911  -0.00653986 -0.8614499 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.01991612  0.36825877 -0.02376886 -0.57083046], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.0272813   0.56370586 -0.03518547 -0.87090564], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.03855541  0.75928825 -0.05260358 -1.17444   ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.05374118  0.5648879  -0.07609238 -0.8987012 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.06503893  0.7609541  -0.0940664  -1.2142991 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.08025802  0.5671632  -0.11835238 -0.9525126 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.09160128  0.37381557 -0.13740264 -0.69923437], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.09907759  0.57054794 -0.15138732 -1.0318211 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.11048855  0.37772834 -0.17202374 -0.79023767], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.11804312  0.18533328 -0.1878285  -0.55623055], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.12174978 -0.00672423 -0.1989531  -0.32810858], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.1216153   0.19059156 -0.20551528 -0.676351  ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.12542713  0.38788635 -0.2190423  -1.0260624 ], reward=1.0, terminated=True, truncated=False\n",
      "..... Episode 4 is started ........\n",
      "  → state=[-0.00550346  0.04407008 -0.04268742  0.04607085]\n",
      "  → action=1, state=[-0.00462206  0.23977733 -0.04176601 -0.25976887], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 1.7348897e-04  4.3546987e-01 -4.6961386e-02 -5.6532735e-01], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.00888289  0.24103713 -0.05826793 -0.28780133], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.01370363  0.4369395  -0.06402396 -0.5982773 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.02244242  0.24276906 -0.0759895  -0.32642856], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.0272978   0.43888605 -0.08251807 -0.64207447], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.03607552  0.63505536 -0.09535956 -0.95956004], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.04877663  0.44133574 -0.11455076 -0.698294  ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.05760334  0.63784397 -0.12851664 -1.0247288 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.07036022  0.4446458  -0.14901122 -0.77500147], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.07925314  0.25185332 -0.16451125 -0.53266484], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.08429021  0.05938074 -0.17516455 -0.2960024 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.08547782  0.25651076 -0.18108459 -0.6384081 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.09060803  0.4536339  -0.19385275 -0.98220646], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[ 0.09968071  0.6507503  -0.21349688 -1.3289793 ], reward=1.0, terminated=True, truncated=False\n",
      "..... Episode 5 is started ........\n",
      "  → state=[ 0.0108504   0.00849936  0.02234143 -0.04312364]\n",
      "  → action=0, state=[ 0.01102038 -0.18693571  0.02147896  0.25652367], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[ 0.00728167 -0.38235763  0.02660944  0.55590326], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[-3.6548256e-04 -5.7784289e-01  3.7727501e-02  8.5684955e-01], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[-0.01192234 -0.3832547   0.05486449  0.57626426], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[-0.01958743 -0.5791011   0.06638978  0.8857139 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[-0.03116946 -0.77505845  0.08410405  1.1985067 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[-0.04667063 -0.97116196  0.10807419  1.5163196 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[-0.06609386 -1.1674128   0.13840058  1.8406904 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=0, state=[-0.08944212 -1.3637649   0.17521438  2.1729622 ], reward=1.0, terminated=False, truncated=False\n",
      "  → action=1, state=[-0.11671741 -1.1707308   0.21867363  1.9390942 ], reward=1.0, terminated=True, truncated=False\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import time\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "\n",
    "episode_number = 5\n",
    "\n",
    "for i in range(episode_number):\n",
    "    \n",
    "    print(f\"..... Episode {i+1} is started ........\")\n",
    "    \n",
    "    state, info_ini = env.reset()\n",
    "    \n",
    "    print(f\"  → state={state}\")\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        env.render()\n",
    "        \n",
    "        action = env.action_space.sample()\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        \n",
    "        print(f\"  → action={action}, state={next_state}, reward={reward}, terminated={terminated}, truncated={truncated}\")\n",
    "        \n",
    "        done = terminated or truncated\n",
    "        \n",
    "        time.sleep(0.1)\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678a6e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
